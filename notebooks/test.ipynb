{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralyticsplus import YOLO, render_result \n",
    "# pip install ultralyticsplus==0.0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing an open source segmentation model\n",
    "\n",
    "We first start with loading an open source model for building segmentation problem and use that to rank the masks. For this experiment, we are looking into https://yolov8.xyz/#/?id=about-the-project repo, look for \"building-segmentation\" to find the relevant model. Let's load it up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_mask(img, mask, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Plots the image with an overlay of the mask in red, resizing the mask to match the image.\n",
    "\n",
    "    Args:\n",
    "    - img (str or numpy array): Path to the image file or image array.\n",
    "    - mask (str or numpy array): Path to the mask file or mask array.\n",
    "    - alpha (float): Transparency for overlaying mask.\n",
    "    \"\"\"\n",
    "\n",
    "    # If img is a path, read the image file\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "\n",
    "    # If mask is a path, read the mask file\n",
    "    if isinstance(mask, str):\n",
    "        mask = cv2.imread(mask)\n",
    "\n",
    "    # Convert image from BGR to RGB for displaying with matplotlib\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize the mask to match the image size\n",
    "    mask_resized = cv2.resize(mask, (img_rgb.shape[1], img_rgb.shape[0]))\n",
    "\n",
    "    # Combine all three channels of the mask by taking the max value across channels\n",
    "    mask = np.clip(np.max(mask_resized, axis=2), 0, 1)\n",
    "\n",
    "    # Create a colored mask (Red where the mask is 1, transparent elsewhere)\n",
    "    colored_mask = np.zeros_like(img_rgb)  # Same shape as img, but all zeros\n",
    "    colored_mask[:, :, 0] = mask * 255  # Red channel gets the mask values\n",
    "\n",
    "    # Overlay the red mask on the original image using alpha blending\n",
    "    overlay_img = cv2.addWeighted(img_rgb, 1 - alpha, colored_mask, alpha, 0)\n",
    "\n",
    "    # Plot the image with the red mask overlay\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(overlay_img)\n",
    "    plt.title(\"Image with Red Mask Overlay\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of all the images and masks in the folder\n",
    "masks = glob(\n",
    "    \"/c/Users/syedd/Documents/mine/DCLC3/data/dataset/training_noisy_labels/*png\"\n",
    ")\n",
    "images = glob(\n",
    "    \"/c/Users/syedd/Documents/mine/DCLC3/data/dataset/training_patches/*png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m80\u001b[39m\n\u001b[1;32m----> 2\u001b[0m plot_image_with_mask(images[idx], masks[idx])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "idx = 80\n",
    "plot_image_with_mask(images[idx], masks[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task #1: Understand the different models and hyperparameters for the model. Tune the model to get the best (doesn't have to be perfect) results. Look at multiple images for this experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = YOLO('keremberke/yolov8m-building-segmentation')\n",
    "\n",
    "# set model parameters\n",
    "model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "model.overrides['max_det'] = 1000  # maximum number of detections per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform inference\n",
    "results = model.predict(images[idx])\n",
    "pred_mask = results[0].masks.masks.cpu().permute(1,2,0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: prediction mask shape is differnt from the input image. Side quest: figure out why?\n",
    "pred_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what the predictions are made of\n",
    "np.unique(pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predicted mask\n",
    "plot_image_with_mask(images[idx], pred_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference using the open source model\n",
    "\n",
    "Task #2 :  Once the model is tuned, run infernce on all the images to get the masks. We will use these masks for ranking the images later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = glob(\"/home/contact_mine_ai/DCLC3/data/dataset/training_noisy_labels/*png\")\n",
    "images = glob(\"/home/contact_mine_ai/DCLC3/data/dataset/training_patches/*png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = YOLO('keremberke/yolov8m-building-segmentation')\n",
    "\n",
    "# set the tuned model parameters\n",
    "model.overrides['conf'] = 0.01  # NMS confidence threshold\n",
    "model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "model.overrides['max_det'] = 100000  # maximum number of detections per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path, msk_path in tqdm(zip(images[80:], masks[80:]), total=len(images)):\n",
    "    # Perform inference\n",
    "    results = model.predict(img_path)\n",
    "    \n",
    "    # Check if masks exist in the result\n",
    "    if results[0].masks is not None and len(results[0].masks.masks) > 0:\n",
    "        # Get the predicted mask (assuming you're working with the first result)\n",
    "        pred_mask = np.max(results[0].masks.masks.cpu().permute(1, 2, 0).numpy(), axis=2)\n",
    "        pred_mask = np.stack([pred_mask] * 3, axis=-1)  # Stack to make it 3 channels (RGB)\n",
    "    else:\n",
    "        # If no mask is predicted, create an empty (black) mask of the same shape as the input image\n",
    "        img = cv2.imread(img_path)  # Read the image to get its dimensions\n",
    "        pred_mask = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)  # Create black mask (3-channel)\n",
    "\n",
    "    # Resize the predicted mask (or empty mask) to 256x256\n",
    "    pred_mask_resized = cv2.resize(pred_mask, (256, 256))\n",
    "\n",
    "    # Create the corresponding output path by replacing 'training_patches' with 'pred_masks'\n",
    "    output_path = img_path.replace('training_patches', 'pred_masks')\n",
    "\n",
    "    # Ensure the output directory exists (for nested directories)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    # Save the resized mask to the output directory\n",
    "    cv2.imwrite(output_path, pred_mask_resized)\n",
    "    \n",
    "    break  # Assuming this is for debugging, you can remove it for the full loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe results\n",
    "print(results[0].boxes)\n",
    "print(results[0].masks)\n",
    "render = render_result(model=model, image=img_path, result=results[0])\n",
    "render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predicted mask\n",
    "plt.imshow(pred_mask_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predicted mask with image\n",
    "plot_image_with_mask(img_path, pred_mask_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mask from dataset\n",
    "plot_image_with_mask(img_path, msk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Eval and Rank the images\n",
    "\n",
    "Task #3 : Using the predicted masks and actual masks, write a function to calculate the IoU metric between them to rank the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
